

ğŸ“˜ AI PDF Q&A Assistant (Event-Driven, Kafka + AIServices RAG + Ollama + Weaviate)

A fully event-driven, asynchronous RAG pipeline using Java 17, Spring Boot 3.2, Kafka, Weaviate, and Ollama for LLM-powered PDF Question-Answering.

Built with clean architecture, loose coupling, AIServices, and production-quality patterns.

â¸»

ğŸš€ Overview

AI PDF Q&A Assistant allows users to:

ğŸ“¤ Upload any PDF

â€“ Extract text
â€“ Chunk it safely
â€“ Remove emoji/noise
â€“ Generate embeddings via Ollama â†’ nomic-embed-text

ğŸ“¦ Store Vectors

â€“ Weaviate (preferred)
or
â€“ PostgreSQL + pgvector

ğŸ¤– Query Using RAG

â€“ Retrieve relevant chunks
â€“ AIServices builds the final prompt
â€“ Mistral (Ollama) answers using ONLY retrieved PDF context
â€“ No hallucinations

âš™ï¸ Entire ingestion is event-driven

PDF processing happens asynchronously through Kafka.

âœ” Non-blocking
âœ” Fault-tolerant
âœ” Horizontally scalable
âœ” Decoupled ingestion pipeline
âœ” Ready for production

â¸»

ğŸ§  Why Kafka?

PDF extraction â†’ chunking â†’ embedding is slow.

Instead of blocking the upload API:

Client Uploads PDF
â†“
REST API produces Kafka event â†’ pdf.ingest
â†“
Kafka Consumer Worker
â†“
Extract â†’ Chunk â†’ Embed â†’ Store vectors

Benefits:
â€¢	âœ” Upload API returns instantly
â€¢	âœ” No timeout issues
â€¢	âœ” Retry on failures
â€¢	âœ” Parallel ingestion workers
â€¢	âœ” Event-driven microservice style

â¸»

ğŸ—ï¸ Tech Stack

Backend
â€¢	Java 17
â€¢	Spring Boot 3.2.x
â€¢	Spring Kafka
â€¢	Spring Web
â€¢	LangChain4j (0.33.0)
â€¢	AIServices API
â€¢	Apache PDFBox

AI & RAG
â€¢	Ollama
â€¢	mistral (chat model)
â€¢	nomic-embed-text (embedding model)
â€¢	RAG using:
â€¢	WeaviateContentRetriever
â€¢	DefaultRetrievalAugmentor
â€¢	AIServices prompt templates

Vector Databases
â€¢	Weaviate (default, best)
â€¢	PostgreSQL + pgvector (optional)

Infra
â€¢	Kafka + Zookeeper
â€¢	Weaviate
â€¢	Docker Compose
â€¢	Ollama (local LLM server)

â¸»

ğŸ“ Updated Project Structure

ai-pdf-qa/
â”œâ”€â”€ controller/
â”‚   â”œâ”€â”€ PdfUploadController.java   <-- Upload endpoint
â”‚   â”œâ”€â”€ PdfQueryController.java    <-- AI Q&A endpoint (AIServices)
â”‚   â””â”€â”€ HealthController.java
â”‚
â”œâ”€â”€ kafka/
â”‚   â”œâ”€â”€ producer/
â”‚   â”‚   â””â”€â”€ PdfIngestProducer.java
â”‚   â”œâ”€â”€ consumer/
â”‚   â”‚   â””â”€â”€ PdfIngestConsumer.java
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â””â”€â”€ PdfUploadedEvent.java
â”‚   â””â”€â”€ KafkaConfig.java
â”‚
â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ PdfTextExtractor.java
â”‚   â”œâ”€â”€ ChunkService.java
â”‚   â”œâ”€â”€ PdfIngestionService.java
â”‚   â”œâ”€â”€ RagConfig.java             <-- AIServices RAG setup
â”‚   â””â”€â”€ PdfQaService.java          <-- AIServices interface
â”‚
â”œâ”€â”€ vector/
â”‚   â”œâ”€â”€ VectorStoreConfig.java
â”‚   â”œâ”€â”€ WeaviateVectorStore.java
â”‚   â””â”€â”€ PgVectorStore.java
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ OllamaConfig.java
â”‚   â”œâ”€â”€ EmbeddingConfig.java
â”‚   â”œâ”€â”€ SwaggerConfig.java
â”‚   â””â”€â”€ AppProperties.java
â”‚
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ Chunk.java
â”‚   â”œâ”€â”€ PdfDocumentMeta.java
â”‚   â”œâ”€â”€ QueryRequest.java
â”‚   â””â”€â”€ QueryResponse.java
â”‚
â”œâ”€â”€ resources/
â”‚   â”œâ”€â”€ application.yaml
â”‚   â”œâ”€â”€ application-dev.yaml
â”‚   â”œâ”€â”€ application-docker.yaml
â”‚   â””â”€â”€ banner.txt
â”‚
â””â”€â”€ PdfQaApplication.java


â¸»

ğŸ”„ Event-Driven RAG Pipeline

1ï¸âƒ£ Upload PDF

POST /api/pdf/upload
â€¢	Saves file temporarily
â€¢	Publishes PdfUploadedEvent to Kafka

2ï¸âƒ£ Kafka Worker

Consumes event â†’ performs:

âœ” PDF text extraction
âœ” Cleanup (remove emojis)
âœ” Chunking (safe chunk sizes)
âœ” Embedding using Ollama (nomic-embed-text)
âœ” Insert vectors into Weaviate
âœ” Attach metadata:

source: <filename>
type: pdf
path: /tmp/...

3ï¸âƒ£ Ask Questions

GET /api/pdf/ask?q=

Using AIServices:
â€¢	Embeds question
â€¢	Retrieves top chunks
â€¢	Builds combined prompt
â€¢	Calls Mistral
â€¢	Returns contextual answer

â¸»

ğŸ¤– AIServices â€” Our RAG Brain

public interface PdfQaService {

    @SystemMessage("""
        You are an expert PDF assistant.
        Use ONLY the retrieved PDF chunks.
        If answer not found: say "I could not find this in the document."
    """)
    @UserMessage("Question: {{question}}")
    String answer(String question);
}

Wiring in RagConfig:

@Bean
public PdfQaService pdfQaService(OllamaChatModel chatModel,
RetrievalAugmentor augmentor) {
return AiServices.builder(PdfQaService.class)
.chatLanguageModel(chatModel)
.retrievalAugmentor(augmentor)
.build();
}


â¸»

ğŸ”¥ REST Endpoints

ğŸ“¤ Upload PDF

POST /api/pdf/upload
file: <PDF>

Response:

"Upload received! PDF is being processed."

ğŸ¤– Ask a question

GET /api/pdf/ask?q=Explain chapter 2

Response:

{
"answer": "Chapter 2 describes...",
"sources": [...]
}


â¸»

ğŸ³ Docker Setup

Start everything:

docker-compose up -d

Includes:
â€¢	Kafka
â€¢	Zookeeper
â€¢	Weaviate
â€¢	Ollama (API enabled)

Run backend:

./gradlew bootRun

Swagger:

http://localhost:8081/swagger-ui.html


â¸»

ğŸ§ª Testing End-to-End

1ï¸âƒ£ Upload a PDF

curl -F "file=@bank-policy.pdf" http://localhost:8081/api/pdf/upload

2ï¸âƒ£ Wait for Kafka worker to index it

3ï¸âƒ£ Ask a question

curl "http://localhost:8081/api/pdf/ask?q=What is the interest rate?"


â¸»

ğŸ”® Roadmap
â€¢	PDF page-level source mapping
â€¢	WebSockets streaming answers
â€¢	Multi-PDF collections
â€¢	User accounts + multi-tenancy
â€¢	Automatic PDF summarization
â€¢	Topic extraction
â€¢	Caching layer for faster queries
â€¢	Hybrid RAG (keyword + semantic search)

â¸»

ğŸ¤ Contributing

PRs welcome!
This repo is built for learning and production-ready experimentation.

â¸»

ğŸ›¡ï¸ License

MIT License

â¸»
